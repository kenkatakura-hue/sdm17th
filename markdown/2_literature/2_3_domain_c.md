# 深層学習モデルの軽量化技術

エッジデバイスやモバイル端末での深層学習モデルの実行を可能にするため、モデルの軽量化技術が盛んに研究されている。主要なアプローチは以下の4つに分類される。

## 効率的なアーキテクチャ設計

MobileNet (Howard et al., 2017) は、Depthwise Separable Convolutionを導入し、計算量を大幅に削減した。EfficientNet (Tan & Le, 2019) は、ネットワークの幅・深さ・解像度を複合的にスケーリングする手法を提案し、パラメータ効率の良いモデルを実現した。ShuffleNet、GhostNetなど、様々な軽量アーキテクチャが提案されている。

## 知識蒸留

大規模な教師モデル（Teacher）の知識を小規模な生徒モデル（Student）に転移する手法である。Hinton et al. (2015) の提案以降、様々な蒸留手法が開発されている。物体検出への適用では、特徴マップレベルでの蒸留が効果的であることが報告されている。

## 枝刈り（Pruning）

ネットワークの重要でないパラメータや構造を削除する手法である。重み枝刈り、フィルタ枝刈り、構造化枝刈りなどの種類がある。モデルサイズの削減と推論速度の向上が期待できるが、精度低下とのトレードオフが課題となる。

## 量子化

浮動小数点数（FP32）で表現された重みを、より低ビットの整数（INT8等）に変換する手法である。モデルサイズの削減と推論速度の向上が実現できる。TensorRT、ONNX Runtimeなどの推論エンジンが量子化をサポートしている。
