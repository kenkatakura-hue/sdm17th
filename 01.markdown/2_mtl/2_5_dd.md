# 詳細設計

各コンポーネントの詳細設計について述べる。

## Neko Attention Moduleの設計

Neko Attention Module（NAM）は、Self-Attentionの変形であり、猫の形態学的特徴領域に重みを集中させる。

計算式は以下の通りである。

$$
\text{NAM}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}} + M_{\text{neko}}\right)V
$$

ここで $M_{\text{neko}}$ は事前学習により獲得した猫特徴マスクである。

## 損失関数

学習には以下の複合損失関数を使用する。

$$
\mathcal{L} = \lambda_1 \mathcal{L}_{\text{cls}} + \lambda_2 \mathcal{L}_{\text{box}} + \lambda_3 \mathcal{L}_{\text{att}}
$$

$\mathcal{L}_{\text{att}}$ はアテンションマップと猫部位アノテーションの一致度を測る正則化項である。
